{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.dataset import FerDataset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ResidualUnit(nn.Module):\n",
    "    \n",
    "    def __init__(self, depth_in, depth_out):\n",
    "        super(ResidualUnit, self).__init__()\n",
    "        self.stride = 1\n",
    "        \n",
    "        self.resBlock = nn.Sequential(\n",
    "            nn.Conv2d(depth_in, depth_out, kernel_size=(3, 3), stride = self.stride, padding = 1),\n",
    "            nn.BatchNorm2d(depth_out),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(depth_out, depth_out, kernel_size=(3, 3), stride = self.stride, padding = 1),\n",
    "            nn.BatchNorm2d(depth_out)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        x = self.resBlock(x)\n",
    "        #print(\"x.shape\", x.shape)\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x += identity\n",
    "        x = nn.ReLU(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DownsampleResidualUnit(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_depth, output_depth):\n",
    "        super(DownsampleResidualUnit, self).__init__()\n",
    "        self.stride = 2\n",
    "        \n",
    "        self.resBlock = nn.Sequential(\n",
    "            nn.Conv2d(depth_in, depth_out, kernel_size=(3, 3), stride = self.stride, padding = 1),\n",
    "            nn.BatchNorm2d(depth_out),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(depth_out, depth_out, kernel_size=(3, 3), stride = 1, padding = 1),\n",
    "            nn.BatchNorm2d(depth_out)\n",
    "        )\n",
    "        \n",
    "        self.matchDim = nn.Sequential(\n",
    "            nn.Conv2d(depth_in, depth_out, kernel_size=(1,1), stride=self.stride, padding = 0),\n",
    "            # this is required to match the dimensions of the identity x with F(x), because\n",
    "            # in this block the first of the two convolutionl layers performs downsamlpling and therefore\n",
    "            # changes the dimensions of the activation volume.\n",
    "            nn.BatchNorm2d(depth_out)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        x = self.resBlock(x)\n",
    "        #print(\"x.shape\", x.shape)\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        \n",
    "        \n",
    "        identity = self.matchDim(identity)\n",
    "        \n",
    "        \n",
    "        x += identity\n",
    "        x = nn.ReLU(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
