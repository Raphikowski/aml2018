{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.dataset import FerDataset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatingUnit(nn.Module):\n",
    "    \"\"\"Gating unit described in 'Convolutional Networks with Adaptive Inference Graphs'.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, gate_dim):\n",
    "        super(GatingUnit, self).__init__()\n",
    "        \n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.estimate_relevance = nn.Sequential(\n",
    "            nn.Linear(in_channels, gate_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(gate_dim, 2))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = self.estimate_relevance(x)\n",
    "        print(x)\n",
    "        x = F.gumbel_softmax(x, tau=1, hard=True)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class AdaptiveConv2d(nn.Module):\n",
    "    \"\"\"Adaptive Conv2d layer described in 'Convolutional Networks with Adaptive Inference Graphs'.\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1, bias=True, gate_dim=16):\n",
    "        super(AdaptiveConv2d, self).__init__()\n",
    "\n",
    "        self.gate = GatingUnit(in_channels, gate_dim)\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride,\n",
    "                              padding, dilation, groups, bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        decision = self.gate(x)\n",
    "        conv_index = decision[:, 1].nonzero().view(-1)\n",
    "        conv_in = x.index_select(0, conv_index)\n",
    "        conv_out = self.conv(x)\n",
    "        \n",
    "        if conv_in.size() != conv_out.size():\n",
    "            # Do Math\n",
    "        else:\n",
    "            # Also do math\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0290, -0.3717],\n",
      "        [ 0.0129, -0.3197],\n",
      "        [ 0.0089, -0.3038],\n",
      "        [ 0.0343, -0.3490],\n",
      "        [ 0.0230, -0.3272],\n",
      "        [ 0.0037, -0.3145],\n",
      "        [ 0.0210, -0.2988],\n",
      "        [ 0.0235, -0.3167],\n",
      "        [ 0.0168, -0.3138],\n",
      "        [ 0.0071, -0.3151],\n",
      "        [-0.0012, -0.3231],\n",
      "        [ 0.0021, -0.3088]], grad_fn=<ThAddmmBackward>)\n",
      "tensor([[0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]], grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.5495, 0.2985, 0.1253, 0.8119, 0.4992],\n",
       "          [0.9188, 0.4821, 0.6444, 0.8395, 0.3465],\n",
       "          [0.8262, 0.9112, 0.6921, 0.8597, 0.3539],\n",
       "          [0.7665, 0.6900, 0.5419, 0.8898, 0.8607],\n",
       "          [0.9310, 0.6509, 0.8718, 0.6782, 0.8211]],\n",
       "\n",
       "         [[0.8046, 0.9768, 0.0070, 0.3013, 0.0972],\n",
       "          [0.9024, 0.3047, 0.8814, 0.1755, 0.0179],\n",
       "          [0.7028, 0.7762, 0.0333, 0.6288, 0.3000],\n",
       "          [0.4325, 0.9721, 0.8618, 0.5498, 0.3575],\n",
       "          [0.0274, 0.1275, 0.6650, 0.7355, 0.1149]],\n",
       "\n",
       "         [[0.7766, 0.6726, 0.3634, 0.6606, 0.2743],\n",
       "          [0.8063, 0.4997, 0.9470, 0.7933, 0.0951],\n",
       "          [0.7158, 0.8008, 0.3565, 0.0465, 0.0358],\n",
       "          [0.9518, 0.8723, 0.0257, 0.7804, 0.4957],\n",
       "          [0.6515, 0.2795, 0.9468, 0.9447, 0.2961]]],\n",
       "\n",
       "\n",
       "        [[[0.4921, 0.6068, 0.5353, 0.9972, 0.2090],\n",
       "          [0.2539, 0.7632, 0.5563, 0.7647, 0.6703],\n",
       "          [0.7683, 0.8440, 0.4695, 0.5384, 0.6641],\n",
       "          [0.4563, 0.9586, 0.3373, 0.8670, 0.9790],\n",
       "          [0.5150, 0.5853, 0.4376, 0.6848, 0.9580]],\n",
       "\n",
       "         [[0.0769, 0.8947, 0.9089, 0.8414, 0.7679],\n",
       "          [0.8738, 0.2932, 0.7353, 0.2246, 0.6123],\n",
       "          [0.1400, 0.0563, 0.0223, 0.4247, 0.0361],\n",
       "          [0.6064, 0.8173, 0.0521, 0.0514, 0.9460],\n",
       "          [0.6989, 0.6259, 0.7446, 0.1095, 0.6359]],\n",
       "\n",
       "         [[0.1937, 0.9954, 0.2701, 0.1053, 0.4014],\n",
       "          [0.3980, 0.1331, 0.4182, 0.5414, 0.6446],\n",
       "          [0.7364, 0.9446, 0.1152, 0.1542, 0.0530],\n",
       "          [0.0406, 0.3999, 0.0220, 0.8237, 0.4081],\n",
       "          [0.1324, 0.0212, 0.1460, 0.0594, 0.5326]]],\n",
       "\n",
       "\n",
       "        [[[0.3685, 0.9562, 0.1748, 0.5248, 0.1994],\n",
       "          [0.7371, 0.9845, 0.8700, 0.4780, 0.8157],\n",
       "          [0.3732, 0.2310, 0.8384, 0.1733, 0.0990],\n",
       "          [0.9361, 0.7454, 0.6514, 0.6995, 0.0127],\n",
       "          [0.3912, 0.2341, 0.5730, 0.2696, 0.0007]],\n",
       "\n",
       "         [[0.2546, 0.4062, 0.8279, 0.6246, 0.6362],\n",
       "          [0.0493, 0.7482, 0.7337, 0.2219, 0.7563],\n",
       "          [0.6783, 0.6995, 0.4540, 0.5768, 0.4292],\n",
       "          [0.1761, 0.9131, 0.9971, 0.2102, 0.4287],\n",
       "          [0.4032, 0.6666, 0.8521, 0.5746, 0.5374]],\n",
       "\n",
       "         [[0.8942, 0.6447, 0.2736, 0.1582, 0.9859],\n",
       "          [0.2249, 0.0033, 0.5223, 0.5548, 0.5344],\n",
       "          [0.5171, 0.6683, 0.5607, 0.8462, 0.2997],\n",
       "          [0.6067, 0.6231, 0.3081, 0.4757, 0.5070],\n",
       "          [0.1610, 0.7003, 0.2183, 0.6115, 0.1448]]],\n",
       "\n",
       "\n",
       "        [[[0.4854, 0.6608, 0.5634, 0.7297, 0.9368],\n",
       "          [0.8101, 0.0465, 0.0577, 0.4389, 0.0414],\n",
       "          [0.4205, 0.5334, 0.3200, 0.5183, 0.9841],\n",
       "          [0.4437, 0.6565, 0.5130, 0.0443, 0.8190],\n",
       "          [0.0862, 0.1429, 0.5126, 0.3888, 0.8427]],\n",
       "\n",
       "         [[0.5630, 0.4180, 0.5225, 0.6018, 0.1791],\n",
       "          [0.2602, 0.2716, 0.4959, 0.9196, 0.6601],\n",
       "          [0.2273, 0.8148, 0.9919, 0.1562, 0.9183],\n",
       "          [0.3091, 0.9259, 0.6621, 0.6486, 0.4812],\n",
       "          [0.2748, 0.2620, 0.4851, 0.1851, 0.2001]],\n",
       "\n",
       "         [[0.9197, 0.1712, 0.9766, 0.3638, 0.4411],\n",
       "          [0.4998, 0.9595, 0.9544, 0.9727, 0.9287],\n",
       "          [0.4266, 0.5780, 0.2463, 0.7752, 0.7953],\n",
       "          [0.0279, 0.4213, 0.2514, 0.1175, 0.4059],\n",
       "          [0.1456, 0.9124, 0.9583, 0.4853, 0.8209]]],\n",
       "\n",
       "\n",
       "        [[[0.7344, 0.6401, 0.9689, 0.1895, 0.9664],\n",
       "          [0.0548, 0.5320, 0.0269, 0.7769, 0.4628],\n",
       "          [0.2157, 0.0745, 0.5054, 0.5360, 0.1259],\n",
       "          [0.0261, 0.3984, 0.6740, 0.6721, 0.7170],\n",
       "          [0.9853, 0.3576, 0.1935, 0.4634, 0.4794]],\n",
       "\n",
       "         [[0.4345, 0.8872, 0.3111, 0.3256, 0.3475],\n",
       "          [0.9944, 0.2607, 0.1301, 0.9518, 0.6276],\n",
       "          [0.3240, 0.6890, 0.2687, 0.8737, 0.7139],\n",
       "          [0.5884, 0.6832, 0.9347, 0.0064, 0.9367],\n",
       "          [0.8283, 0.2104, 0.8352, 0.2083, 0.0610]],\n",
       "\n",
       "         [[0.9335, 0.0998, 0.1578, 0.7997, 0.9819],\n",
       "          [0.2964, 0.1714, 0.6420, 0.8781, 0.1108],\n",
       "          [0.4044, 0.2925, 0.4767, 0.9175, 0.7725],\n",
       "          [0.1973, 0.8489, 0.0575, 0.1695, 0.7753],\n",
       "          [0.1323, 0.6565, 0.4841, 0.8730, 0.6323]]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(12, 3, 5, 5)\n",
    "gate = GatingUnit(in_channels=3, hidden_layer_dim=16)\n",
    "cond = gate(x)\n",
    "conv_index = cond[:, 1].nonzero().view(-1)\n",
    "conv_input = x.index_select(0, conv_index)\n",
    "conv_weights = weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0100, 0.7428, 0.1073, 0.0196, 0.1097])\n",
      "tensor([0.0100, 0.7428])\n",
      "tensor([0.0100, 0.7428, 0.1073, 0.0196, 0.1097])\n",
      "tensor([0.0001, 0.5517])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5)\n",
    "print(x)\n",
    "y = x.index_select(0, torch.LongTensor([0, 1]))\n",
    "print(y)\n",
    "y = y**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond.nonzero?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0., -2.],\n",
       "        [ 0.,  0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(2, 3, 5, 5)\n",
    "[]\n",
    "out = x[0, 1].pow(2).sum()\n",
    "out.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.where?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = np.arange(0, 16).reshape(4, 4)\n",
    "x = np.array([c, c, c])[np.newaxis, ...]\n",
    "x = torch.from_numpy(x).float()\n",
    "y = F.adaptive_avg_pool2d(x, 1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.index_put_?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
